# Google Colab Cells - Visual Guide

This guide shows exactly what each cell looks like in your Colab notebook.

---

## ğŸ“‹ Cell Overview

| Cell # | Type | What It Does | Time |
|--------|------|-------------|------|
| 1 | Text | Title and intro | - |
| 2 | Text | Setup instructions | - |
| 3 | Code | **Install packages** | 2-3 min |
| 4 | Text | âš ï¸ Restart reminder | - |
| 5 | Text | Model loading instructions | - |
| 6 | Code | **Load gpt-oss-20b** | 3-5 min |
| 7 | Text | Dataset instructions | - |
| 8 | Code | **Load dataset from HuggingFace** | 30 sec |
| 9 | Text | Helper functions header | - |
| 10 | Code | **Define helper functions** | Instant |
| 11 | Text | Test one sample header | - |
| 12 | Code | **Test generation on 1 problem** | 5-10 sec |
| 13 | Text | Batch evaluation header | - |
| 14 | Code | **Run evaluation (10+ samples)** | 30 sec - 2 hrs |
| 15 | Text | Save results header | - |
| 16 | Code | **Save and download results** | Instant |
| 17 | Text | Optional comparison header | - |
| 18 | Code | **Compare reasoning efforts** | 1-2 min |

---

## ğŸ“± Cell-by-Cell Preview

### Cell 1: Title (Markdown)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ # GPT-OSS 20B Evaluation on LeetCode Dataset          â”‚
â”‚                                                        â”‚
â”‚ This notebook evaluates OpenAI's gpt-oss-20b model    â”‚
â”‚ on the LeetCode contests dataset.                     â”‚
â”‚                                                        â”‚
â”‚ **Requirements**:                                      â”‚
â”‚ - Free Google Colab (T4 GPU)                          â”‚
â”‚ - HuggingFace account (to load dataset)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### Cell 2: Setup Instructions (Markdown)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ## Step 1: Setup Environment                          â”‚
â”‚                                                        â”‚
â”‚ Install required packages for mxfp4 quantization      â”‚
â”‚ support.                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### Cell 3: Install Packages (Code) âš™ï¸
```python
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ # Install bleeding-edge PyTorch and transformers      â”‚
â”‚ !pip install -q --upgrade torch                       â”‚
â”‚ !pip install -q transformers triton==3.4 kernels      â”‚
â”‚ !pip uninstall -q torchvision torchaudio -y           â”‚
â”‚                                                        â”‚
â”‚ # Install datasets library                            â”‚
â”‚ !pip install -q datasets                              â”‚
â”‚                                                        â”‚
â”‚ â–¶ [Run this cell]                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Expected Output:**
```
Installing...
Successfully installed torch-2.x.x
Successfully installed transformers-4.x.x
Successfully installed triton-3.4
Successfully installed kernels-x.x.x
Successfully installed datasets-x.x.x
```

---

### Cell 4: Restart Reminder (Markdown) âš ï¸
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ âš ï¸ **IMPORTANT**: Please restart your Colab runtime   â”‚
â”‚ after running the cell above.                          â”‚
â”‚                                                        â”‚
â”‚ Click: **Runtime â†’ Restart runtime**                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ACTION REQUIRED**:
1. Click "Runtime" in menu
2. Click "Restart runtime"
3. Wait for session to restart
4. **DO NOT** re-run Cell 3

---

### Cell 5: Model Loading Header (Markdown)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ## Step 2: Load GPT-OSS 20B Model                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### Cell 6: Load Model (Code) ğŸ¤–
```python
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ from transformers import AutoModelForCausalLM,         â”‚
â”‚                          AutoTokenizer                 â”‚
â”‚ import torch                                           â”‚
â”‚                                                        â”‚
â”‚ print("Loading gpt-oss-20b model...")                 â”‚
â”‚ print(f"CUDA available: {torch.cuda.is_available()}")â”‚
â”‚ print(f"CUDA device: {torch.cuda.get_device_name(0)}")â”‚
â”‚                                                        â”‚
â”‚ model_id = "openai/gpt-oss-20b"                       â”‚
â”‚                                                        â”‚
â”‚ tokenizer = AutoTokenizer.from_pretrained(model_id)   â”‚
â”‚ model = AutoModelForCausalLM.from_pretrained(         â”‚
â”‚     model_id,                                          â”‚
â”‚     torch_dtype="auto",                                â”‚
â”‚     device_map="cuda",                                 â”‚
â”‚ )                                                      â”‚
â”‚                                                        â”‚
â”‚ print("âœ“ Model loaded successfully!")                 â”‚
â”‚                                                        â”‚
â”‚ â–¶ [Run this cell]                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Expected Output:**
```
Loading gpt-oss-20b model...
CUDA available: True
CUDA device: Tesla T4

Downloading model files...
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 100%
Loading checkpoint shards: 100% 2/2 [01:30<00:00, 45.2s/it]

âœ“ Model loaded successfully!
```

â±ï¸ **Time**: 3-5 minutes (first time only)

---

### Cell 7: Dataset Header (Markdown)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ## Step 3: Load LeetCode Dataset from HuggingFace     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### Cell 8: Load Dataset (Code) ğŸ“Š
```python
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ from datasets import load_dataset                      â”‚
â”‚                                                        â”‚
â”‚ # TODO: Replace with your HuggingFace dataset repo ID â”‚
â”‚ DATASET_REPO_ID = "YOUR_USERNAME/leetcode-contests-431-467" â”‚
â”‚                                                        â”‚
â”‚ print(f"Loading dataset from {DATASET_REPO_ID}...")   â”‚
â”‚ dataset = load_dataset(DATASET_REPO_ID)               â”‚
â”‚                                                        â”‚
â”‚ print(f"\nâœ“ Dataset loaded!")                         â”‚
â”‚ print(f"Total samples: {len(dataset['train'])}")      â”‚
â”‚ print(f"\nFirst sample:")                             â”‚
â”‚ sample = dataset['train'][0]                          â”‚
â”‚ print(f"  ID: {sample['id']}")                        â”‚
â”‚ print(f"  Function: {sample['function_name']}")       â”‚
â”‚ print(f"  Difficulty: {sample['difficulty']}")        â”‚
â”‚                                                        â”‚
â”‚ â–¶ [Run this cell]                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**âš ï¸ IMPORTANT**: Change this line:
```python
# CHANGE THIS:
DATASET_REPO_ID = "YOUR_USERNAME/leetcode-contests-431-467"

# TO THIS (with your HF username):
DATASET_REPO_ID = "akshitgaur/leetcode-contests-431-467"
```

**Expected Output:**
```
Loading dataset from akshitgaur/leetcode-contests-431-467...
Downloading data files: 100%
Generating train split: 347/347 [00:00<00:00, 12345.67 examples/s]

âœ“ Dataset loaded!
Total samples: 347

First sample:
  ID: contest431_q3702_s0
  Function: maxLength
  Difficulty: easy
  Input: maxLength(nums=[1,2,1,2,1,1,1])...
```

â±ï¸ **Time**: 10-30 seconds

---

### Cell 9-10: Helper Functions
```python
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ # Helper functions for code generation and testing    â”‚
â”‚                                                        â”‚
â”‚ def build_prompt(sample: Dict) -> str:                â”‚
â”‚     """Build prompt for code generation"""            â”‚
â”‚     # ... code ...                                     â”‚
â”‚                                                        â”‚
â”‚ def extract_code_from_response(response: str) -> str: â”‚
â”‚     """Extract Python code from model response"""     â”‚
â”‚     # ... code ...                                     â”‚
â”‚                                                        â”‚
â”‚ def execute_code_with_test(...) -> Tuple[bool, str]:  â”‚
â”‚     """Execute generated code and check correctness"""â”‚
â”‚     # ... code ...                                     â”‚
â”‚                                                        â”‚
â”‚ print("âœ“ Helper functions defined")                   â”‚
â”‚                                                        â”‚
â”‚ â–¶ [Run this cell]                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Expected Output:**
```
âœ“ Helper functions defined
```

â±ï¸ **Time**: Instant

---

### Cell 11-12: Test One Sample (Code) ğŸ§ª
```python
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ # Test with one sample                                 â”‚
â”‚ test_sample = dataset['train'][0]                     â”‚
â”‚                                                        â”‚
â”‚ # Build prompt and generate code                      â”‚
â”‚ messages = [...]                                       â”‚
â”‚ inputs = tokenizer.apply_chat_template(               â”‚
â”‚     messages,                                          â”‚
â”‚     reasoning_effort="medium",  # â† CONFIGURABLE      â”‚
â”‚ ).to(model.device)                                    â”‚
â”‚                                                        â”‚
â”‚ print("Generating code...")                           â”‚
â”‚ generated = model.generate(**inputs, max_new_tokens=500)â”‚
â”‚ response = tokenizer.decode(...)                      â”‚
â”‚                                                        â”‚
â”‚ # Test correctness                                     â”‚
â”‚ is_correct, error = execute_code_with_test(...)       â”‚
â”‚ print(f"Test Result: {'âœ“' if is_correct else 'âœ—'}")   â”‚
â”‚                                                        â”‚
â”‚ â–¶ [Run this cell]                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Expected Output:**
```
Prompt:
Write a Python function to solve this LeetCode problem:

Function to implement: maxLength
...

============================================================
Generating code...

Generated Response:
Here's a solution:

```python
def maxLength(nums):
    n = len(nums)
    ans = 0
    for l in range(n):
        # ... implementation
    return ans
```

============================================================
Extracted Code:
def maxLength(nums):
    n = len(nums)
    ans = 0
    ...

============================================================
Test Result: âœ“ CORRECT
Expected: 5
```

â±ï¸ **Time**: 5-10 seconds per sample

---

### Cell 13-14: Batch Evaluation (Code) ğŸš€
```python
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ # Configuration                                        â”‚
â”‚ NUM_SAMPLES = 10  # â† START SMALL, INCREASE LATER    â”‚
â”‚ REASONING_EFFORT = "medium"  # low/medium/high        â”‚
â”‚                                                        â”‚
â”‚ results = []                                           â”‚
â”‚ correct_count = 0                                      â”‚
â”‚                                                        â”‚
â”‚ for idx in tqdm(range(NUM_SAMPLES)):                 â”‚
â”‚     sample = dataset['train'][idx]                    â”‚
â”‚                                                        â”‚
â”‚     # Generate code                                    â”‚
â”‚     # ... generation logic ...                         â”‚
â”‚                                                        â”‚
â”‚     # Test correctness                                 â”‚
â”‚     is_correct, error = execute_code_with_test(...)   â”‚
â”‚     if is_correct:                                     â”‚
â”‚         correct_count += 1                             â”‚
â”‚                                                        â”‚
â”‚ # Print results                                        â”‚
â”‚ print(f"pass@1: {correct_count/NUM_SAMPLES*100:.2f}%")â”‚
â”‚                                                        â”‚
â”‚ â–¶ [Run this cell]                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Expected Output:**
```
Evaluating 10 samples with reasoning_effort=medium...

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:45<00:00, 4.5s/it]

============================================================
EVALUATION RESULTS
============================================================
Model: gpt-oss-20b
Reasoning effort: medium
Total samples: 10
Correct: 7
pass@1: 70.00%
Average latency: 3.45s
============================================================

By Difficulty:
  Easy: 3/3 (100.0%)
  Medium: 3/5 (60.0%)
  Hard: 1/2 (50.0%)
```

â±ï¸ **Time**:
- 10 samples: ~30-60 seconds
- 50 samples: ~3-5 minutes
- 347 samples: ~1-2 hours

**ğŸ’¡ TIP**: Start with `NUM_SAMPLES = 10` to test!

---

### Cell 15-16: Save Results (Code) ğŸ’¾
```python
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ import json                                            â”‚
â”‚ from datetime import datetime                          â”‚
â”‚                                                        â”‚
â”‚ output_filename = f"gpt_oss_20b_results_{...}.json"   â”‚
â”‚                                                        â”‚
â”‚ output_data = {                                        â”‚
â”‚     "model": "gpt-oss-20b",                           â”‚
â”‚     "pass_at_1": correct_count / NUM_SAMPLES,         â”‚
â”‚     "results": results                                 â”‚
â”‚ }                                                      â”‚
â”‚                                                        â”‚
â”‚ with open(output_filename, 'w') as f:                 â”‚
â”‚     json.dump(output_data, f, indent=2)               â”‚
â”‚                                                        â”‚
â”‚ # Download the file                                    â”‚
â”‚ from google.colab import files                        â”‚
â”‚ files.download(output_filename)                       â”‚
â”‚                                                        â”‚
â”‚ â–¶ [Run this cell]                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Expected Output:**
```
âœ“ Results saved to: gpt_oss_20b_results_medium_20250120_143022.json

[Browser download popup appears]
â¬‡ï¸ Downloading: gpt_oss_20b_results_medium_20250120_143022.json
```

File is saved to your Downloads folder!

---

## ğŸ¯ Quick Action Checklist

When you open the notebook:

- [ ] **Cell 3**: Run install packages â†’ Wait for completion
- [ ] **IMPORTANT**: Runtime â†’ Restart runtime
- [ ] **Cell 6**: Run to load model (3-5 min wait)
- [ ] **Cell 8**: **EDIT** `DATASET_REPO_ID` with your username, then run
- [ ] **Cell 10**: Run to define helpers
- [ ] **Cell 12**: Run to test 1 sample
- [ ] **Cell 14**: **EDIT** `NUM_SAMPLES = 10`, then run
- [ ] **Cell 16**: Run to download results

---

## âš™ï¸ Customization Points

### Change Number of Samples
```python
# In Cell 14
NUM_SAMPLES = 10    # Quick test
NUM_SAMPLES = 50    # Medium test
NUM_SAMPLES = 347   # Full dataset (1-2 hours!)
```

### Change Reasoning Effort
```python
# In Cell 14
REASONING_EFFORT = "low"     # Faster, less accurate
REASONING_EFFORT = "medium"  # Balanced (recommended)
REASONING_EFFORT = "high"    # Slower, more accurate
```

### Change Max Tokens
```python
# In Cell 12 or 14
generated = model.generate(**inputs, max_new_tokens=500)  # Default
generated = model.generate(**inputs, max_new_tokens=300)  # Shorter
generated = model.generate(**inputs, max_new_tokens=1000) # Longer
```

---

## ğŸ› Common Issues

### "Runtime disconnected"
**Solution**: Keep tab active or use Colab Pro

### "CUDA out of memory"
**Solution**: Reduce `max_new_tokens` to 300

### "Dataset not found"
**Solution**: Check `DATASET_REPO_ID` matches your HuggingFace repo

### "Model download stuck"
**Solution**: Wait 5 minutes, or restart runtime and try again

---

## ğŸ“Š Expected Performance

Based on similar models:

| Reasoning | pass@1 | Time/sample |
|-----------|--------|-------------|
| Low | 55-65% | ~2s |
| Medium | 60-70% | ~3s |
| High | 65-75% | ~5s |

---

This is what your Colab notebook will look like! Ready to run? ğŸš€
